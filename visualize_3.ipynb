{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numbers\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from datasets import get_dataset\n",
    "\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {dataset_name: get_dataset(dataset_name) for dataset_name in [\"Is_Acyclic_Ones\", \"MUTAG\", \"Shapes_Ones\"]}\n",
    "dataset_name = \"Shapes_Ones\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(adjacency_matrix, node_features):\n",
    "    \"\"\"\n",
    "    Create a NetworkX graph from a numpy adjacency matrix and node feature matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - adjacency_matrix (numpy.ndarray): The adjacency matrix of the graph.\n",
    "    - node_features (numpy.ndarray): The matrix of node features.\n",
    "\n",
    "    Returns:\n",
    "    - nx.Graph: The created NetworkX graph.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an empty graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Get the number of nodes in the graph\n",
    "    num_nodes = adjacency_matrix.shape[0]\n",
    "\n",
    "    # Add nodes to the graph with corresponding features\n",
    "    for i in range(num_nodes):\n",
    "        G.add_node(i, label=node_features[i])\n",
    "\n",
    "    # Add edges to the graph based on the adjacency matrix\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            if adjacency_matrix[i, j] != 0:\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "    return G\n",
    "\n",
    "def average_edit_distance(Gs):\n",
    "    # Get the average edit distance between all pairs of graphs\n",
    "    average_edit_distances = []\n",
    "    for i in range(len(Gs)):\n",
    "        edit_distances = []\n",
    "        for j in range(len(Gs)):\n",
    "            edit_distances.append(nx.graph_edit_distance(Gs[i], Gs[j], node_match=lambda x, y: np.isclose(x['label'], y['label']).all()))\n",
    "        average_edit_distances.append(np.mean(edit_distances))   \n",
    "    return np.mean(average_edit_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "gdir = \"./results/all_info/\"\n",
    "d_list = []\n",
    "for filename in os.listdir(gdir):\n",
    "    try:\n",
    "        if d[\"dataset_name\"] != dataset_name:\n",
    "            continue\n",
    "        d = pickle.load(open(gdir+filename, \"rb\"))\n",
    "        d[\"run_id\"] = filename.split(\".\")[0]\n",
    "        d[\"max_class_name\"] = datasets[d[\"dataset_name\"]].GRAPH_CLS[d[\"max_class\"]]\n",
    "        d_list.append(d)\n",
    "    except Exception:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d_list[1][\"mip_information\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(d_list[0].keys()), d_list[0][\"solutions\"][-1], d_list[0][\"mip_information\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in d_list:\n",
    "    if not d[\"num_nodes\"] == 8 or not d[\"dataset_name\"] == \"Shapes_Ones\":\n",
    "        continue\n",
    "    print(\"Ah\")\n",
    "    d[\"mip_information\"] = pd.DataFrame(d[\"mip_information\"])\n",
    "    d[\"mip_information\"].rename(columns={\"BestBound\": \"Best Bound\", \"ObjBound\": \"Objective Bound\", \"WorkUnits\": \"Work Units\", \"ExploredNodeCount\": \"Explored Node Count\", \"UnexploredNodeCount\": \"Unexplored Node Count\"}, inplace=True)\n",
    "    fig = px.line(d[\"mip_information\"], \n",
    "    x=\"Work Units\", \n",
    "    y=[\"Best Bound\", \"Objective Bound\"], \n",
    "    title=\"Convergence of Objective Bounds\", \n",
    "    width=1000, \n",
    "    height=800,\n",
    "    log_y = True)\n",
    "    fig.update_layout(\n",
    "        font=dict(\n",
    "            family= \"Roman Modern\",\n",
    "            size=18,\n",
    "            color='rgb(82, 82, 82)',\n",
    "        ),\n",
    "    xaxis=dict(\n",
    "        ticks='outside',\n",
    "        tickfont=dict(\n",
    "            size=18,\n",
    "            color='rgb(82, 82, 82)',\n",
    "        ),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Objective Value\",\n",
    "        tickfont=dict(\n",
    "            size=18,\n",
    "            color='rgb(82, 82, 82)',\n",
    "        ),\n",
    "    ),\n",
    "    # legend=dict(\n",
    "    #     visible=False\n",
    "    # ),\n",
    "    showlegend=False,\n",
    "    autosize=False,\n",
    "    margin=dict(\n",
    "        autoexpand=True,\n",
    "        l=100,\n",
    "        r=20,\n",
    "        t=110,\n",
    "    ),\n",
    ")   \n",
    "    # Save figure\n",
    "    fig.write_image(f\"./results/figures/convergence_{d['dataset']}_class_{d['max_class']}_n_{d['num_nodes']}_id_{d['run_id']}.png\")\n",
    "    # fig.write_html(\"./results/figures/convergence_{d['dataset']}_class_{d['max_class']}_n_{d['num_nodes']}_id_{d['run_id']}.html\") \n",
    "    # fig.show()\n",
    "\n",
    "\n",
    "    fig = px.line(d[\"mip_information\"], \n",
    "    x=\"Work Units\", \n",
    "    y=[\"Explored Node Count\", \"Unexplored Node Count\"], \n",
    "    title=\"Node Counts\", \n",
    "    width=1000, \n",
    "    height=800,\n",
    "    log_y = True)\n",
    "    fig.update_layout(\n",
    "        font=dict(\n",
    "            family= \"Roman Modern\",\n",
    "            size=18,\n",
    "            color='rgb(82, 82, 82)',\n",
    "        ),\n",
    "    xaxis=dict(\n",
    "        ticks='outside',\n",
    "        tickfont=dict(\n",
    "            size=18,\n",
    "            color='rgb(82, 82, 82)',\n",
    "        ),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Number of Nodes\",\n",
    "        tickfont=dict(\n",
    "            size=18,\n",
    "            color='rgb(82, 82, 82)',\n",
    "        ),\n",
    "    ),\n",
    "    showlegend=True,\n",
    "    autosize=False,\n",
    "    margin=dict(\n",
    "        autoexpand=True,\n",
    "        l=100,\n",
    "        r=20,\n",
    "        t=110,\n",
    "    ),\n",
    "    )   \n",
    "    fig.write_image(f\"./results/figures/node_counts_{d['dataset']}_class_{d['max_class']}_n_{d['num_nodes']}_id_{d['run_id']}.png\")\n",
    "    # fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mipexplainer_df = pd.DataFrame([{key: value for key, value in d.items() if isinstance(value, numbers.Number) or key in {\"run_id\", \"dataset_name\"}} for d in d_list])\n",
    "\n",
    "mipexplainer_df[\"G\"] = [create_graph(d[\"solutions\"][-1][\"A\"], d[\"solutions\"][-1][\"X\"]) for d in d_list]\n",
    "mipexplainer_df[\"init_G\"] = [create_graph(d[\"solutions\"][0][\"A\"], d[\"solutions\"][0][\"X\"]) for d in d_list]\n",
    "mipexplainer_df[\"method\"] = \"MIPExplainer\"\n",
    "\n",
    "mipexplainer_df = mipexplainer_df[mipexplainer_df[\"dataset_name\"]==dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnninterpreter_df = pd.DataFrame(pickle.load(open(f\"results/gnninterpreter_{dataset_name}.pkl\", \"rb\")))\n",
    "xgnn_df = pd.DataFrame(pickle.load(open(f\"results/xgnn_{dataset_name}.pkl\", \"rb\")))\n",
    "\n",
    "df = pd.concat([mipexplainer_df, gnninterpreter_df, xgnn_df])\n",
    "index_names = [\"dataset_name\", \"max_class\", \"num_nodes\", \"method\"] \n",
    "\n",
    "df = df[df[\"max_class\"] != 4]\n",
    "\n",
    "df = df.set_index(index_names).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df[[f\"Output Logit {i}\" for i in range(4)]].copy() # df[[c for c in df.columns if \"Output Logit\" in c]]\n",
    "a.rename(columns={f\"Output Logit {i}\": f\"{datasets[dataset_name].GRAPH_CLS[i]} Output Logit\" for i in range(datasets[dataset_name].num_classes)}, inplace=True)\n",
    "# a = a.div(a.sum(axis=1)**2, axis=0)\n",
    "logit_table = a.groupby(index_names).mean()\n",
    "with open(f\"results/tables/output_logit_{dataset_name}.tex\", \"w\") as f:\n",
    "    f.write(logit_table.to_latex(index=True, float_format=\"{:.3f}\".format).replace(\"_\", \"\\\\_\"))\n",
    "logit_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_table = df.groupby(index_names)[\"runtime\"].mean()\n",
    "with open(f\"results/tables/runtime_{dataset_name}.tex\", \"w\") as f:\n",
    "    f.write(runtime_table.to_latex(index=True, float_format=\"{:.3f}\".format).replace(\"_\", \"\\\\_\"))\n",
    "runtime_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "for name, group in tqdm(df.groupby(index_names)[\"G\"]):\n",
    "    # Save the average edit distance of the group to a df\n",
    "    group = list(group)\n",
    "    distances.append({\"Consistency\": average_edit_distance(group)} | dict(zip(index_names, name)))\n",
    "distances_df = pd.DataFrame(distances).set_index(index_names).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/tables/consistency_{dataset_name}.tex\", \"w\") as f:\n",
    "    f.write(distances_df.to_latex(index=True, float_format=\"{:.3f}\".format).replace(\"_\", \"\\\\_\"))\n",
    "runtime_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average over num_nodes\n",
    "averaged_distances_df = distances_df.groupby([\"dataset_name\", \"max_class\", \"method\"]).mean()\n",
    "with open(f\"results/tables/averaged_consistency_{dataset_name}.tex\", \"w\") as f:\n",
    "    f.write(averaged_distances_df.to_latex(index=True, float_format=\"{:.3f}\".format).replace(\"_\", \"\\\\_\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "InvertGNNs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
